# 7장 신뢰성 있는 데이터 전달
카프카를 사용하여 신뢰성을 검증하는 방법에 대해서 알아가보자 <br>

## 7.1 신뢰성 보장
제일 잘 알려진 신뢰성 보장은 RDBMS 에서 지원하는 ACID 일 것이다 <br>
- A(Atomicity): 원자성
- C(Consistency): 일관성
- I(Isolation): 격리성
- D(Durability): 지속성

어떠한 데이터베이스가 ACID 를 준수한다고 하면, 트랜잭션 처리 관련해서 어떠한 행동을 보장한다는 의미가 된다 <br>

신뢰성 있는 어플리케이션을 개발하고자 한다면 Kafka 에서 제공하는 보장을 이해하는 것은 필수적이다.
- Kafka 는 파티션 안의 메시지들 간에 순서를 보장한다.
- 클라이언트가 쓴 메시지는 InSync 레플리카의 파티션에 쓰여진 뒤에야 '커밋' 된 것으로 간주된다 (디스크 flush 까지는 필요 없다)
- 커밋된 메시지들은 최소 1개의 작동 가능한 레플리카가 남아 있는 한 유실되지 않는다.
- 컨슈머는 커밋된 메시지만 읽을 수 있다.

위처럼 기본적인 보장들은 제공하지만, 신뢰성 시스템을 구축하는 데는 트레이드 오프가 있는 법이다 <br>
보통 신뢰성이냐, 일관성이냐, 가용성이냐 높은 처리량이냐 이러한 고민을 하게 된다 <br><br>

## 7.2 복제
카프카의 복제 메커니즘은 파티션별로 다수의 레플리카를 유지한다는 특성과 함께 카프카의 신뢰성 보장의 핵심이라고 할 수 있다 <br>
하나의 메시지를 여러 개의 레플리카에 씀으로써 카프카는 crash 가 나더라도 메시지의 지속성을 유지한다 <br>

하나의 파티션은 하나의 디스크에 저장되며, 저장된 이벤트들의 순서를 보장하며, 파티션은 온라인 상태거나 오프라인 상태일 수 있다 <br>
각 파티션은 다수의 레플리카를 가질 수 있으며, 그 중 하나가 리더가 된다 <br>
️🖐🏽브로커 개수에 따라서 레플리카가 존재하며, 리더 브로커에 있는 토픽의 파티션이 리더가 된다로 이해를 했는데 이부분이 맞는지 체크하기 <br>

모든 이벤트들은 리더 레플리카에 쓰여지며, 리더 리플레카에서 읽혀진다, 다른 레플리카들은 단순히 리더와 동기화를 맞추면서 최신 이벤트를 복사해 오기만 하면 된다 <br>
리더가 crash 되면, 인-싱크 레플리카 중 하나가 새 리더가 된다 <br><br>


## 7.3 브로커 설정
메시지 저장 신뢰성 관련된 카프카의 작동을 변경시키는 브로커의 설정 매개변수는 세 개가 있다

### 7.3.1 복제 팩터
토픽을 생성할 때 복제 팩터를 설정한다 (replication.factor) <br>
자동으로 생성될 경우 브로커의 default.replication.factor 설정에 잡힌대로 생성을 한다 <br>

복제 팩터 설정을 3이라고 한다면, 3개의 카프카 브로커가 있을 경우 3개 브로커 전체에 토픽이 복제가 된다는 뜻이다 <br>
ex) 카프카 브로커5개, 복제 팩터 3개 -> 카프카 브로커 5개중 3개의 브로커에만 토픽이 복제가 된다 <br>

복제 팩터가 클수록 가용성과 신뢰성은 늘어나고 장애가 발생할 확률은 줄어든다 <br>
하지만 그 만큼 메시지를 저장할 디스크 공간이 필요하다는 이야기도 된다 <br>
기본적으로, 가용성과 하드웨어 사용량 사이에 트레이드오프가 있는 것이다 <br>

그렇다면 토픽에 몇개의 복제 팩터가 적절한지 모범 사례 설정을 보자 <br>
- 가용성: 레플리카 수가 많을 수록 가용성은 늘어난다
- 지속성: 레플리카 수가 많을 수록 데이터 유실 가능성이 줄어든다.
- 처리량: 레플리카가 추가될 때 마다 브로커간 트래픽 역시 늘어난다. 
- 종단 지연: 쓰여진 메시지를 컨슈머가 읽으려면 InSync 설정에 잡힌 브로커(레플리카)에 복제가 되어야한다. -> 느려진다.
- 비용: 더 많은 레플리카를 가질수록 저장소와 네트워크에 들어가는 비용 역시 증가한다.

실제 레플리카가 존재하는 위치 역시 중요하다 <br>
같은 랙에 설치되어 있는데 랙이 오작동 할경우 해당 파티션은 사용할 수 없다 <br>
broker.rack 브로커 설정 매겨변수에 브로커 별로 서로 다른 이름을 잡아줄 것을 권장한다 <br>


### 7.3.2 언클린 리더 선출
위 설정은 브로커 단위에서만 가능하다(unclean.leader.election.enable=false (default))<br>

파티션의 리더가 사용 불가능 일 경우, 인-싱크 레플리카 중 하나가 새 리더가 된다 <br>
커밋된 데이터에 아무런 유실이 없음을 보장한다는 점에서 이러한 리더 선출을 '클린' 하다고 부른다 <br>

우리가 아웃-오브 싱크 레플리카(동기화X) 리더가 될 수 있도록 허용할 경우 데이터 유실과 일관성 깨짐의 위험성이 있다 <br>
그렇지 않을 경우, 파티션이 다시 온라인 상태가 될 때까지 원래 리더가 복구되는 것을 기다려야 하는 만큼 가용성은 줄어든다 <br>

-> unclean.leader.election.enable=false default 설정을 권장한다 <br>
불가피한 상황이 왔을 경우 true 로 변경 후 나중에 안정화가 되면 false 로 바꾸는 것이 권장됨. <br>


### 7.3.3 최소 인-싱크 레플리카
토픽, 브로커 단위 모두 min.insync.replicas 설정을 통해 잡아줄 수 있다 <br>
3개의 브로커 중 팔로워 2개가 죽을 경우, 가용성과 일관성 사이에서 하나를 골라야 한다 <br>

위 경우 min.insync.replicas=2 일 경우 브로커는 더 이상 쓰기 요청을 받을 수 없다 <br>
NotEnoughReplicasException 을 받게 된다 <br>

### 7.3.4 레플리카를 인-싱크 상태로 유지하기
out-of-sync-replicas 는 신뢰성을 낮추므로 가능한 피할 필요가 있다 <br>

### 7.3.5 디스크에 저장하기

## 7.4 신뢰성 있는 시스템에서 프로듀서 사용하기
- 언클린 리더 선출 기능을 끈다 -> 카프카 클러스터에 커밋된 메시지는 유실되지 않는다.
- 프로듀서 설정이 acks=-1 이 아니라, acks=1 이라면?
  - 리더에는 쓰였지만, in-sync-replicas 에는 반영되지 않았다.

### 7.4.1 응답 보내기
#### acks=0
in-sync-replicas 가 필요없이 1개의 메시지가 전송되면 성공으로 간주한다 <br>
그러므로 지연율이 낮다.

#### acks=1
이것은 리더가 메시지를 받아서 파티션 데이터 파일에 쓴 직후 응답 또는 에러를 보낸다는 것을 의미한다 (하드 디스크 반영과 별개)<br>
위 설정을 사용할 경우 메시지를 복제하는 속도보다 더 빨리 리더에 쓸 수 있기 때문에 불완전 복제 파티션이 발생할 수 있다. <br>
-> 리더 입장에서 복제가 완료되기 전에 프로듀서에게 응답 먼저 하기 때문이다.

#### acks=all (acks=-1)
in-sync-replicas 에 복제가 완료될 때 까지 기다린 후 복제가 완료되면 성공 응답을 준다 <br>
가장 안전한 옵션이지만, 지연이 가장 길어지는 옵션이다


### 7.4.2 프로듀서 재시도 설정하기
프로듀서는 재시도 가능한 에러를 처리할 수 있다 <br>
- 전송을 재시도 하면 해결되는 에러 -> 재처리
  - ex) LEADER_NOT_AVAILABLE
- 전송을 재시도 해도 해결되지 않는 에러 -> 재처리 불가 에러 응답
  - INVALID_CONFIG

즉, 메시지 유실을 방지하기 위해 재시도 가능한 에러가 발생할 경우 프로듀서가 계속해서 메시지 전송을 재시도하도록 설정하는 것이다 <br>
재시도 가장 좋은 방법, 재시도 수 기본 값(무한), 메시지 전송을 포기할 때 까지 대기할 수 있는 시간 delivery.timeout.ms 설정 값 잡기 <br>

-> 하지만 재시도는 중복 메시지를 발행할 수 있기에 이 부분은 방지해야 한다.

#### 7.4.3 추가적인 에러처리
-> DLQ 설정?

## 7.5 신뢰성 있는 시스템에서 컨슈머 사용하기
컨슈머는 카프카에 커밋된 데이터만 읽을 수 있다 -> 모든 in-sync-replicas 에 쓰인 후 읽을 수 있다 <br>
즉, 컨슈머는 일관성이 보장되는 데이터만 읽을 수 있다 <br>
컨슈머가 해야할 일은 어느 메시지까지 읽었고, 어디까지 읽지 않았는지 추적해야 한다. 이것은 메시지를 읽는 도중에 누락되지 않게 하기 위해서 필수적이다 <br>

파티션으로부터 데이터를 읽어올 때 컨슈머는 메시지를 배치 단위로 읽어온 뒤 배치별로 마지막 오프셋을 확인한 뒤, 브로커로부터 받은 오프셋 값에서 시작하는 다른 메시지 배치를 요청한다 <br>

특정 카프카 컨슈머가 작동을 정지하면, 또 다른 컨슈머 입장에서는 어디서부터 작업을 재개해야 할지 알아야 할 필요가 있다.
- 이전 컨슈머가 정지되기 전 마지막 읽은 오프셋은 어딘지? 
각 파티션에 대해 어디까지 읽었는지를 저장해 둬야 해당 컨슈머나 다른 컨슈머가 재시작한 뒤에도 어디서부터 작업을 계속해야 할지 알 수 있기 때문이다 <br>

> 커밋된 메시지 vs 커밋된 오프셋
> > 커밋된 메시지 -> 모든 in-sync-replicas 쓰여져 컨슈머가 읽을 수 있는 메시지 <br>
> > 커밋된 오프셋 -> 컨슈머가 특정 파티션 어느 오프셋까지의 모든 메시지를 받아서 처리를 완료했는지를 알리기 위해 카프카에 보낸 오프셋 <br>

### 7.5.1 신뢰성 있는 처리를 위해 중요한 컨슈머 설정
#### 1. group.id
같은 group.id 를 가지는 2개의 컨슈머가 같은 토픽을 구독할 경우, 각각의 컨슈머에 다른 파티션이 할당되어 서로 다른 부분의 메시지만을 읽게 된다 <br>
만약 컨슈머가 구독한 토픽의 모든 메시지를 읽어야하면 고유한 그룹 ID 가 필요하다 <br>

#### 2. auto.offset.reset
위 매개변수는 커밋된 오프셋이 없을 때나 컨슈머가 브로커에 없는 오프셋을 요청할 때 컨슈머가 어떻게 해야할지를 결정한다 <br>
- ealiest: 유효한 오프셋이 없으면 맨 앞에서부터 읽기를 시작한다.
  - 메시지 중복 처리 위험은 있지만, 메시지 유실은 최소화 할 수 있다.
- latest: 컨슈머는 파티션 끝에서 부터 읽기 시작
  - 메시지 중복 처리는 최소화 하지만, 메시지 유실은 확실하게 될 것이다.

#### 3. enable.auto.commit
일정 시간에 맞춰 컨슈머가 알아서 오프셋을 커밋할지? 아니면 코드에서 직접 오프셋을 커밋할지? <br>

자동 오프셋 기능을 주된 단점은 메시지 중복 처리를 우리가 제어할 수 없다는 점이다 <br>
읽어온 메시지 중 일부만 처리하고, 아직 자동 커밋이 되지 않은 상태에서 컨슈머가 멈추면, 컨슈머를 다시 기동시 메시지 중복 처리 문제를 피할 수 없다 <br>

애플리케이션이 백그라운드에서 처리를 수행하기 위해 다른 스레드에 레코드를 넘기는 것과 같이 더 복잡한 처리를 해야 할 경우, 직접 오프셋을 커밋해주는 것 외에는 선택지가 없다 <br>
자동 커밋 기능이 컨슈머가 읽어오기는 했지만, 아직 처리하지는 않은 오프셋을 커밋할 수도 있기 때문이다 <Br>

#### 4. auto.commit.inverval.ms
enable.auto.commit 과 관련된 설정이다 <br>
만약 오프셋을 자동으로 커밋할 경우, 이 설정을 사용해서 커밋되는 주기를 설정할 수 있다 <br>
기본값은 5초이며, 일반적으로 커밋이 자주 일어날수록 오버헤드가 늘어나지만, 컨슈머가 정지했을 때 발생하는 중복 처리는 줄어든다 <br>

만약 컨슈머가 리밸런스를 수행하기 위해 너무 자주 멈추면, 신뢰성이 있다고 하기는 어려울 것이다 <br>
불필요한 리밸런싱과 리밸런싱이 발생했을 때의 멈춤을 최소화하기 위해서는 어떻게 컨슈머를 설정해야 하는가도 필수적으로 알아야 한다 <br>

### 7.5.2 컨슈머에서 명시적으로 오프셋 커밋하기
세밀한 제어가 필요하여 오프셋 커밋을 직접 수행하기로 했다면, 위 결정이 정확성과 성능에 미치는 영향에도 신경 쓸 필요가 있다 <br>

#### 1. 메시지 처리 먼저, 오프셋 커밋은 나중에

#### 2. 커밋 빈도는 성능과 크래시 발생시 중복 개수 사이의 트레이드 오프
커밋 작업은 성능 오버헤드를 수반한다 <br>

#### 3. 정확한 시점에 정확한 오프셋을 커밋하자
폴링 루프 중간에서 커밋할 때 흔히 발생하는 실수는 마지막으로 처리된 메시지의 오프셋이 아닌, 마지막으로 읽어 온 메시지의 오프셋을 커밋하는 것이다 <br>
언제나 처리가 완료된 메시지의 오프셋을 커밋하는 것이 중요하다는 것을 기억하자 <br>
읽기는 했지만, 처리되지 않은 메시지의 오프셋을 커밋할 경우 컨슈머 입장에서는 메시지가 누락될 수 있다 <br>

#### 4. 리밸런스
컨슈머 리밸런스가 발생할 것이라는 것과 이것을 적절히 처리해 줄 필요가 있다 <br>
보통 할당된 파티션이 해제되기 전에 오프셋을 커밋하고, 새로운 파티션이 할당되었을 때 애플리케이션이 보유하고 있던 상태를 삭제해주는 작업을 포함한다 <br>

#### 5. 컨슈머는 재시도를 해야할 수도 있다.
-> DLQ 시스템과 비슷함

#### 6. 컨슈머가 상태를 유지해야할 수도 있다.

## 7.6 시스템 신뢰성 검증하기
### 7.6.1 설정 검증하기
클라이언트 <-> 브로커 간의 검증이 필요하다 <br>
카프카는 검증릉 위해 VerifiableProducer, VerifiableConsumer 를 제공한다 

테스트 시나리오
- 리더 선출 테스트
- 컨트롤러 선출 테스트
- 롤링 재시작 테스트
- 언클린 리더 선출 테스트 

### 7.6.2 애플리케이션 검증하기
클라이언트 <-> 브로커 설정이 요구조건과 맞다는걸 확인했다면, 이제 어플리케이션이 우리가 필요로 하는 보장을 해주는지를 확인해야 한다 <br>
위 테스트는 통합 테스트를 수행하는 것을 권장하며, 다양한 장애상황에 대해 테스트를 수행할 것 역시 권장한다 <br>

### 7.6.3 프로덕션 환경에서 신뢰성 모니터링하기
카프카의 자바 클라이언트들은 클라이언트 쪽 상태와 이벤트를 모니터링할 수 있게 해주는 JMX 지표를 포함한다 <br>
프로듀서의 경우, 신뢰성 측면에서 가장 중요한 두 지표는 레코드별 에러율, 재시도율이다 <br>

컨슈머 쪽에서 가장 중요한 지표는 컨슈머 랙(Lack) 이다 <br>

